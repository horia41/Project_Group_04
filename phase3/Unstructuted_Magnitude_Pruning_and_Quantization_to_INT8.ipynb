{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 1. Unstructured Magnitude Pruning - finding lazy neurons (whose weights is for e.g. 0.000032) and turning them off",
   "id": "ac245f63a5f3c231"
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from cswin_fpn_hybrid.resnet50_cswin.new_model import ResNetCSWinHybrid\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils.prune as prune\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from torchvision.transforms import v2\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "import os\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    data_transforms = {\n",
    "        'train': v2.Compose([\n",
    "            v2.Resize((224, 224)),\n",
    "            # ------------------------------------ baseline augmentation\n",
    "            # v2.RandomHorizontalFlip(),\n",
    "            # v2.RandomVerticalFlip(),\n",
    "            # v2.ToTensor(),\n",
    "            # v2.Normalize([0.7553, 0.3109, 0.1059], [0.1774, 0.1262, 0.0863]),\n",
    "            # ------------------------------------ baseline augmentation\n",
    "\n",
    "            # ------------------------------------ new data augmentation added\n",
    "\n",
    "            # Geometric Transforms\n",
    "            v2.RandomHorizontalFlip(p=0.5),\n",
    "\n",
    "            v2.RandomRotation(degrees=15),\n",
    "            # Slight zoom/shift\n",
    "            v2.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "\n",
    "            # Color/Signal Transforms\n",
    "            v2.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3),\n",
    "\n",
    "            # Noise & Robustness\n",
    "            # Gaussian Blur helps ignore grain/noise\n",
    "            v2.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0)),\n",
    "\n",
    "            v2.ToTensor(),\n",
    "            # train 2022\n",
    "            v2.Normalize([0.7083, 0.2776, 0.0762], [0.1704, 0.1296, 0.0815]),\n",
    "            # train 2019\n",
    "            # v2.Normalize([0.7553, 0.3109, 0.1059], [0.1774, 0.1262, 0.0863]),\n",
    "\n",
    "            # Occlusion (The Precision Booster)\n",
    "            v2.RandomErasing(p=0.3, scale=(0.02, 0.15), ratio=(0.3, 3.3)),\n",
    "            # --------------------------------- new data augmentation added\n",
    "        ]),\n",
    "        'test': v2.Compose([\n",
    "            v2.Resize((224, 224)),\n",
    "            v2.ToTensor(),\n",
    "            # train 2022\n",
    "            v2.Normalize([0.7083, 0.2776, 0.0762], [0.1704, 0.1296, 0.0815])\n",
    "            # train 2019\n",
    "            # v2.Normalize([0.7553, 0.3109, 0.1059], [0.1774, 0.1262, 0.0863])\n",
    "        ]),\n",
    "    }\n",
    "\n",
    "    data_dir = 'DeepLearning_PlantDiseases-master/Scripts/PlantVillage_2_2022train_2019test'\n",
    "    # data_dir = 'DeepLearning_PlantDiseases-master/Scripts/PlantVillage_1_2019train_2022test'\n",
    "\n",
    "    dsets = {split: datasets.ImageFolder(os.path.join(data_dir, split), data_transforms[split])\n",
    "             for split in ['train', 'test']}\n",
    "\n",
    "    dset_loaders = {\n",
    "        'train': torch.utils.data.DataLoader(dsets['train'], batch_size=batch_size, shuffle=True, num_workers=4),\n",
    "        'test' : torch.utils.data.DataLoader(dsets['test'],  batch_size=batch_size, shuffle=False, num_workers=4),\n",
    "    }\n",
    "\n",
    "    return dset_loaders['train'], dset_loaders['test']\n",
    "\n",
    "def measure_sparsity(model):\n",
    "    # Calculates what % of the model is zeros\n",
    "    total_params = 0\n",
    "    zero_params = 0\n",
    "\n",
    "    for name, module in model.named_modules():\n",
    "        # check for standard layers\n",
    "        if isinstance(module, (nn.Conv2d, nn.Linear)):\n",
    "            # \"weight\" is the parameter\n",
    "            if hasattr(module, \"weight\"):\n",
    "                w = module.weight.data\n",
    "                total_params += w.numel()\n",
    "                zero_params += torch.sum(w == 0).item()\n",
    "\n",
    "    print(f\"Global Sparsity: {100. * zero_params / total_params:.2f}%\")\n",
    "    return zero_params / total_params\n",
    "\n",
    "def apply_pruning(model, amount_cnn, amount_trans):\n",
    "    print(f\"\\nStarting Pruning\")\n",
    "    print(f\"Target is {amount_cnn*100}% on ResNet part, {amount_trans*100}% on Transformer part\")\n",
    "    cnn_count, trans_count = 0, 0\n",
    "\n",
    "    for name, module in model.named_modules():\n",
    "        # We need to prune both Conv2d and Linear layers\n",
    "        if isinstance(module, (nn.Conv2d, nn.Linear)):\n",
    "            if \"stage3\" in name or \"stage4\" in name:\n",
    "                prune.l1_unstructured(module, name='weight', amount=amount_trans)\n",
    "                trans_count += 1\n",
    "            else:\n",
    "                prune.l1_unstructured(module, name='weight', amount=amount_cnn)\n",
    "                cnn_count += 1\n",
    "\n",
    "    print(f\"Pruning Applied: {cnn_count} layers at {amount_cnn} rate, {trans_count} layers at {amount_trans} rate.\")\n",
    "    print(\"Zeros injected.\")\n",
    "\n",
    "def simple_evaluate(model, loader, device, threshold):\n",
    "    #  quick eval to check damage\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in loader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            probs = torch.softmax(outputs, dim=1)[:, 1]\n",
    "            preds = (probs >= threshold).long()\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "\n",
    "    acc = accuracy_score(all_targets, all_preds)\n",
    "    f1 = f1_score(all_targets, all_preds)\n",
    "    return acc, f1\n",
    "\n",
    "\n",
    "def check_parameter_coverage(model):\n",
    "    total_params = 0\n",
    "    prunable_params = 0\n",
    "\n",
    "    print(f\"\\nPruning Coverage Analysis\")\n",
    "\n",
    "    for name, module in model.named_modules():\n",
    "        # Check if the module has parameters\n",
    "        if hasattr(module, 'weight') and module.weight is not None:\n",
    "            params = module.weight.numel()\n",
    "            total_params += params\n",
    "\n",
    "            # Is it one of the types we are targeting?\n",
    "            if isinstance(module, (nn.Conv2d, nn.Linear)):\n",
    "                prunable_params += params\n",
    "            else:\n",
    "                # These are the ones we are skipping\n",
    "                print(f\"Skipping: {name:<40} | Type: {type(module).__name__:<15} | Size: {params}\")\n",
    "\n",
    "    coverage = (prunable_params / total_params) * 100\n",
    "    print(\"-\" * 75)\n",
    "    print(f\"Total Params (Weights only): {total_params:,}\")\n",
    "    print(f\"Targeted Params (Conv+Linear): {prunable_params:,}\")\n",
    "    print(f\"Coverage: {coverage:.2f}%\")\n",
    "\n",
    "    if coverage > 95:\n",
    "        print(\"all good\")\n",
    "    else:\n",
    "        print(\"changed needed\")\n",
    "\n",
    "\n",
    "\n",
    "# 1. Load best Model\n",
    "model = ResNetCSWinHybrid(num_classes=2, resnet_pretrained=True, cswin_pretrained=True)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "batch_size = 128\n",
    "\n",
    "path = 'threshold_0.27_hybrid_Tr2022_Te2019.pth'\n",
    "model.load_state_dict(torch.load(path))\n",
    "\n",
    "trainloader, testloader = load_data()\n",
    "\n",
    "# 2. baseline stats\n",
    "# 0.27 for train 2022, test 2019\n",
    "# 0.07 for train 2019, test 2022\n",
    "threshold = 0.27\n",
    "acc_before, f1_before = simple_evaluate(model, testloader, device, threshold)\n",
    "# acc_before = 0.8908\n",
    "# f1_before = 0.8623\n",
    "print(f\"No pruning baseline acc, f1: {acc_before:.4f}, {f1_before:.4f}\")\n",
    "\n",
    "# 3. apply Pruning\n",
    "apply_pruning(model, amount_cnn=0.08, amount_trans=0.08)\n",
    "measure_sparsity(model)\n",
    "\n",
    "# 4. Check 'Broken' Stats (Before fine-tuning)\n",
    "print(\"Checking Pruned Accuracy (No Retraining)\")\n",
    "acc_after, f1_after = simple_evaluate(model, testloader, device, threshold)\n",
    "print(f\"Pruned Accuracy, F1: {acc_after:.4f}, {f1_after:.4f}\")\n",
    "print(f\"Drop due to pruning: {(acc_before - acc_after)*100:.2f}%, {(f1_before - f1_after)*100:.2f}%\")\n",
    "\n",
    "\n",
    "# Sanity check, see if rights params are targeted\n",
    "# check_parameter_coverage(model)\n",
    "\n",
    "# Note: Pruning adds 'mask' buffers. To make it permanent/saveable:\n",
    "# for name, module in model.named_modules():\n",
    "#     if isinstance(module, (nn.Conv2d, nn.Linear)):\n",
    "#         prune.remove(module, 'weight')"
   ],
   "id": "694a6fc124046936"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 1.2.1 Switch to structured pruning instead (unstructured is hardware dependent)\n",
    "# This is the one shot version"
   ],
   "id": "9e49ec5543cd6e3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils.prune as prune\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from torchvision.transforms import v2\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "import os\n",
    "from cswin_fpn_hybrid.resnet50_cswin.new_model import ResNetCSWinHybrid\n",
    "import torch.functional as F\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    data_transforms = {\n",
    "        'train': v2.Compose([\n",
    "            v2.Resize((224, 224)),\n",
    "            # ------------------------------------ baseline augmentation\n",
    "            # v2.RandomHorizontalFlip(),\n",
    "            # v2.RandomVerticalFlip(),\n",
    "            # v2.ToTensor(),\n",
    "            # v2.Normalize([0.7553, 0.3109, 0.1059], [0.1774, 0.1262, 0.0863]),\n",
    "            # ------------------------------------ baseline augmentation\n",
    "\n",
    "            # ------------------------------------ new data augmentation added\n",
    "\n",
    "            # Geometric Transforms\n",
    "            v2.RandomHorizontalFlip(p=0.5),\n",
    "\n",
    "            v2.RandomRotation(degrees=15),\n",
    "            # Slight zoom/shift\n",
    "            v2.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "\n",
    "            # Color/Signal Transforms\n",
    "            v2.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3),\n",
    "\n",
    "            # Noise & Robustness\n",
    "            # Gaussian Blur helps ignore grain/noise\n",
    "            v2.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0)),\n",
    "\n",
    "            v2.ToTensor(),\n",
    "            # v2.Normalize([0.7083, 0.2776, 0.0762], [0.1704, 0.1296, 0.0815]),\n",
    "            v2.Normalize([0.7553, 0.3109, 0.1059], [0.1774, 0.1262, 0.0863]),\n",
    "\n",
    "            # Occlusion (The Precision Booster)\n",
    "            v2.RandomErasing(p=0.3, scale=(0.02, 0.15), ratio=(0.3, 3.3)),\n",
    "            # --------------------------------- new data augmentation added\n",
    "        ]),\n",
    "        'test': v2.Compose([\n",
    "            v2.Resize((224, 224)),\n",
    "            v2.ToTensor(),\n",
    "            # v2.Normalize([0.7083, 0.2776, 0.0762], [0.1704, 0.1296, 0.0815])\n",
    "            v2.Normalize([0.7553, 0.3109, 0.1059], [0.1774, 0.1262, 0.0863])\n",
    "        ]),\n",
    "    }\n",
    "\n",
    "    # data_dir = 'DeepLearning_PlantDiseases-master/Scripts/PlantVillage_2_2022train_2019test'\n",
    "    data_dir = 'DeepLearning_PlantDiseases-master/Scripts/PlantVillage_1_2019train_2022test'\n",
    "\n",
    "    dsets = {split: datasets.ImageFolder(os.path.join(data_dir, split), data_transforms[split])\n",
    "             for split in ['train', 'test']}\n",
    "\n",
    "    dset_loaders = {\n",
    "        'train': torch.utils.data.DataLoader(dsets['train'], batch_size=batch_size, shuffle=True, num_workers=4),\n",
    "        'test' : torch.utils.data.DataLoader(dsets['test'],  batch_size=batch_size, shuffle=False, num_workers=4),\n",
    "    }\n",
    "\n",
    "    return dset_loaders['train'], dset_loaders['test']\n",
    "\n",
    "def measure_sparsity(model):\n",
    "    # Calculates what % of the model is zeros\n",
    "    total_params = 0\n",
    "    zero_params = 0\n",
    "\n",
    "    for name, module in model.named_modules():\n",
    "        # check for standard layers\n",
    "        if isinstance(module, (nn.Conv2d, nn.Linear)):\n",
    "            # \"weight\" is the parameter\n",
    "            if hasattr(module, \"weight\"):\n",
    "                w = module.weight.data\n",
    "                total_params += w.numel()\n",
    "                zero_params += torch.sum(w == 0).item()\n",
    "\n",
    "    print(f\"Global Sparsity: {100. * zero_params / total_params:.2f}%\")\n",
    "    return zero_params / total_params\n",
    "\n",
    "def apply_pruning(model, amount_cnn, amount_trans):\n",
    "    print(f\"\\nStarting Pruning\")\n",
    "    print(f\"Target is {amount_cnn*100}% on ResNet part, {amount_trans*100}% on Transformer part\")\n",
    "    cnn_count, trans_count = 0, 0\n",
    "\n",
    "    for name, module in model.named_modules():\n",
    "\n",
    "        # prune Conv2d (ResNet/Bridge)\n",
    "        # prune 'dim=0' to remove entire output filters\n",
    "        if isinstance(module, nn.Conv2d):\n",
    "            prune.ln_structured(module, name='weight', amount=amount_cnn, n=2, dim=0)\n",
    "            cnn_count += 1\n",
    "\n",
    "        # prune Linear Layers\n",
    "        elif isinstance(module, nn.Linear):\n",
    "            if \"stage3\" in name or \"stage4\" in name:\n",
    "                # transformers -> sensitive to dimension changes\n",
    "                # prune 'dim=0' (output neurons) to be safe\n",
    "                prune.ln_structured(module, name='weight', amount=amount_trans, n=2, dim=0)\n",
    "                trans_count += 1\n",
    "            else:\n",
    "                # classifier head / bridge linear layers\n",
    "                prune.ln_structured(module, name='weight', amount=amount_cnn, n=2, dim=0)\n",
    "                cnn_count += 1\n",
    "\n",
    "    print(f\"Pruning Applied: {cnn_count} layers at {amount_cnn} rate, {trans_count} layers at {amount_trans} rate.\")\n",
    "    print(\"Zeros injected.\")\n",
    "\n",
    "def simple_evaluate(model, loader, device, threshold):\n",
    "    #  quick eval to check damage\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in loader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            probs = torch.softmax(outputs, dim=1)[:, 1]\n",
    "            preds = (probs >= threshold).long()\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "\n",
    "    acc = accuracy_score(all_targets, all_preds)\n",
    "    f1 = f1_score(all_targets, all_preds)\n",
    "    return acc, f1\n",
    "\n",
    "\n",
    "def check_parameter_coverage(model):\n",
    "    total_params = 0\n",
    "    prunable_params = 0\n",
    "\n",
    "    print(f\"\\nPruning Coverage Analysis\")\n",
    "\n",
    "    for name, module in model.named_modules():\n",
    "        # Check if the module has parameters\n",
    "        if hasattr(module, 'weight') and module.weight is not None:\n",
    "            params = module.weight.numel()\n",
    "            total_params += params\n",
    "\n",
    "            # Is it one of the types we are targeting?\n",
    "            if isinstance(module, (nn.Conv2d, nn.Linear)):\n",
    "                prunable_params += params\n",
    "            else:\n",
    "                # These are the ones we are skipping\n",
    "                print(f\"Skipping: {name:<40} | Type: {type(module).__name__:<15} | Size: {params}\")\n",
    "\n",
    "    coverage = (prunable_params / total_params) * 100\n",
    "    print(\"-\" * 75)\n",
    "    print(f\"Total Params (Weights only): {total_params:,}\")\n",
    "    print(f\"Targeted Params (Conv+Linear): {prunable_params:,}\")\n",
    "    print(f\"Coverage: {coverage:.2f}%\")\n",
    "\n",
    "    if coverage > 95:\n",
    "        print(\"all good\")\n",
    "    else:\n",
    "        print(\"changed needed\")\n",
    "\n",
    "\n",
    "\n",
    "# 1. Load best Model\n",
    "model = ResNetCSWinHybrid(num_classes=2, resnet_pretrained=True, cswin_pretrained=True)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "batch_size = 128\n",
    "\n",
    "# path = 'threshold_0.27_hybrid_Tr2022_Te2019.pth'\n",
    "path = 'threshold_0.07_hybrid_Tr2019_Te2022.pth'\n",
    "model.load_state_dict(torch.load(path))\n",
    "\n",
    "trainloader, testloader = load_data()\n",
    "\n",
    "# 2. baseline stats\n",
    "# 0.27 for train 2022, test 2019\n",
    "# 0.07 for train 2019, test 2022\n",
    "threshold = 0.07\n",
    "\n",
    "# acc_before, f1_before = simple_evaluate(model, testloader, device, threshold)\n",
    "# print(f\"No pruning baseline acc, f1: {acc_before:.4f}, {f1_before:.4f}\")\n",
    "acc_before = 0.8476\n",
    "f1_before = 0.8882\n",
    "\n",
    "# 3. apply Pruning\n",
    "apply_pruning(model, amount_cnn=0.15, amount_trans=0.17)\n",
    "measure_sparsity(model)\n",
    "\n",
    "# 4. Check 'Broken' Stats (Before fine-tuning)\n",
    "print(\"Checking Pruned Accuracy (No Retraining)\")\n",
    "acc_after, f1_after = simple_evaluate(model, testloader, device, threshold)\n",
    "print(f\"Pruned Accuracy, F1: {acc_after:.4f}, {f1_after:.4f}\")\n",
    "print(f\"Drop due to pruning: {(acc_before - acc_after)*100:.2f}%, {(f1_before - f1_after)*100:.2f}%\")"
   ],
   "id": "4e3d8f8579ec2121"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1.2.2 Iterative structured pruning (according to the paper Charis mentioned)",
   "id": "f74c1e686a0c9b89"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils.prune as prune\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import copy\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from torchvision.transforms import v2\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "import os\n",
    "from cswin_fpn_hybrid.resnet50_cswin.new_model import ResNetCSWinHybrid\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "\n",
    "        pt = torch.exp(-ce_loss)\n",
    "\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    data_transforms = {\n",
    "        'train': v2.Compose([\n",
    "            v2.Resize((224, 224)),\n",
    "            # ------------------------------------ baseline augmentation\n",
    "            # v2.RandomHorizontalFlip(),\n",
    "            # v2.RandomVerticalFlip(),\n",
    "            # v2.ToTensor(),\n",
    "            # v2.Normalize([0.7553, 0.3109, 0.1059], [0.1774, 0.1262, 0.0863]),\n",
    "            # ------------------------------------ baseline augmentation\n",
    "\n",
    "            # ------------------------------------ new data augmentation added\n",
    "\n",
    "            # Geometric Transforms\n",
    "            v2.RandomHorizontalFlip(p=0.5),\n",
    "\n",
    "            v2.RandomRotation(degrees=15),\n",
    "            # Slight zoom/shift\n",
    "            v2.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "\n",
    "            # Color/Signal Transforms\n",
    "            v2.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3),\n",
    "\n",
    "            # Noise & Robustness\n",
    "            # Gaussian Blur helps ignore grain/noise\n",
    "            v2.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0)),\n",
    "\n",
    "            v2.ToTensor(),\n",
    "            # v2.Normalize([0.7083, 0.2776, 0.0762], [0.1704, 0.1296, 0.0815]),\n",
    "            v2.Normalize([0.7553, 0.3109, 0.1059], [0.1774, 0.1262, 0.0863]),\n",
    "\n",
    "            # Occlusion (The Precision Booster)\n",
    "            v2.RandomErasing(p=0.3, scale=(0.02, 0.15), ratio=(0.3, 3.3)),\n",
    "            # --------------------------------- new data augmentation added\n",
    "        ]),\n",
    "        'test': v2.Compose([\n",
    "            v2.Resize((224, 224)),\n",
    "            v2.ToTensor(),\n",
    "            # v2.Normalize([0.7083, 0.2776, 0.0762], [0.1704, 0.1296, 0.0815])\n",
    "            v2.Normalize([0.7553, 0.3109, 0.1059], [0.1774, 0.1262, 0.0863])\n",
    "        ]),\n",
    "    }\n",
    "\n",
    "    # data_dir = 'DeepLearning_PlantDiseases-master/Scripts/PlantVillage_2_2022train_2019test'\n",
    "    data_dir = 'DeepLearning_PlantDiseases-master/Scripts/PlantVillage_1_2019train_2022test'\n",
    "\n",
    "    dsets = {split: datasets.ImageFolder(os.path.join(data_dir, split), data_transforms[split])\n",
    "             for split in ['train', 'test']}\n",
    "\n",
    "    dset_loaders = {\n",
    "        'train': torch.utils.data.DataLoader(dsets['train'], batch_size=batch_size, shuffle=True, num_workers=4),\n",
    "        'test' : torch.utils.data.DataLoader(dsets['test'],  batch_size=batch_size, shuffle=False, num_workers=4),\n",
    "    }\n",
    "\n",
    "    return dset_loaders['train'], dset_loaders['test']\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def measure_sparsity(model):\n",
    "    total_params = 0\n",
    "    zero_params = 0\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, (nn.Conv2d, nn.Linear)):\n",
    "            if hasattr(module, \"weight\"):\n",
    "                w = module.weight.data\n",
    "                total_params += w.numel()\n",
    "                zero_params += torch.sum(w == 0).item()\n",
    "    print(f\"Global Sparsity: {100. * zero_params / total_params:.2f}%\")\n",
    "    return zero_params / total_params\n",
    "\n",
    "def simple_evaluate(model, loader, device, threshold):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in loader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            probs = torch.softmax(outputs, dim=1)[:, 1]\n",
    "            preds = (probs >= threshold).long()\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "    acc = accuracy_score(all_targets, all_preds)\n",
    "    f1 = f1_score(all_targets, all_preds)\n",
    "    return acc, f1\n",
    "\n",
    "def get_pruning_rate_per_step(final_target, k_steps):\n",
    "    # ensures that after k steps, exactly final_target % is removed\n",
    "    if final_target <= 0: return 0.0\n",
    "    return 1 - (1 - final_target) ** (1 / k_steps)\n",
    "\n",
    "def apply_structured_pruning_step(model, rate_cnn, rate_trans):\n",
    "    # applies one round of structured pruning using L2 norm (n=2)\n",
    "    count = 0\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, nn.Conv2d):\n",
    "            # Prune output filters (dim=0) using L2 norm\n",
    "            prune.ln_structured(module, name='weight', amount=rate_cnn, n=2, dim=0)\n",
    "            count += 1\n",
    "        elif isinstance(module, nn.Linear):\n",
    "            # Prune output neurons (dim=0)\n",
    "            if \"stage3\" in name or \"stage4\" in name:\n",
    "                prune.ln_structured(module, name='weight', amount=rate_trans, n=2, dim=0)\n",
    "            else:\n",
    "                prune.ln_structured(module, name='weight', amount=rate_cnn, n=2, dim=0)\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "def make_pruning_permanent(model):\n",
    "    # burn mask into the weights so the next step treats the zeros as non-existent\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, (nn.Conv2d, nn.Linear)):\n",
    "            if prune.is_pruned(module):\n",
    "                prune.remove(module, 'weight')\n",
    "\n",
    "def fine_tune_epoch(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "    return running_loss / len(loader.dataset)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "batch_size = 128\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "trainloader, testloader = load_data()\n",
    "\n",
    "model = ResNetCSWinHybrid(num_classes=2, resnet_pretrained=True, cswin_pretrained=True)\n",
    "path = 'threshold_0.07_hybrid_Tr2019_Te2022.pth'\n",
    "model.load_state_dict(torch.load(path))\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "FINAL_CNN_TARGET = 0.15\n",
    "FINAL_TRANS_TARGET = 0.17\n",
    "STEPS = 6                 # k=6 (Paper Recommendation)\n",
    "EPOCHS_PER_STEP = 10\n",
    "THRESHOLD = 0.07\n",
    "\n",
    "cnn_step_rate = get_pruning_rate_per_step(FINAL_CNN_TARGET, STEPS)\n",
    "trans_step_rate = get_pruning_rate_per_step(FINAL_TRANS_TARGET, STEPS)\n",
    "\n",
    "print(f\"Goal: {FINAL_CNN_TARGET*100}% resnet, {FINAL_TRANS_TARGET*100}% trans\")\n",
    "print(f\"Schedule: {STEPS} steps, {EPOCHS_PER_STEP} epochs/step\")\n",
    "print(f\"Per step pruning rate - resnet: {cnn_step_rate:.4f}, trans: {trans_step_rate:.4f}\")\n",
    "\n",
    "acc_base, f1_base = simple_evaluate(model, testloader, device, THRESHOLD)\n",
    "print(f\"Baseline before acc: {acc_base:.4f}, F1: {f1_base:.4f}\\n\")\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5) # low LR for gentle fine-tuning\n",
    "criterion = FocalLoss(gamma=2.0).to(device) # use same loss function during initial training\n",
    "\n",
    "for step in range(1, STEPS + 1):\n",
    "    print(f\"Step {step}/{STEPS}\")\n",
    "\n",
    "    # prune\n",
    "    print(\"Applying pruning\")\n",
    "    apply_structured_pruning_step(model, cnn_step_rate, trans_step_rate)\n",
    "    measure_sparsity(model)\n",
    "\n",
    "    # rehab\n",
    "    print(f\"Finetuning for {EPOCHS_PER_STEP} epochs\")\n",
    "    for epoch in range(EPOCHS_PER_STEP):\n",
    "        loss = fine_tune_epoch(model, trainloader, optimizer, criterion, device)\n",
    "        if (epoch+1) % 5 == 0:\n",
    "            print(f\"   Epoch {epoch+1}/{EPOCHS_PER_STEP} | Loss: {loss:.4f}\")\n",
    "\n",
    "    # check status\n",
    "    acc, f1 = simple_evaluate(model, testloader, device, THRESHOLD)\n",
    "    print(f\"Step {step} result: acc: {acc:.4f} (drop: {(acc_base-acc)*100:.2f}%)\")\n",
    "\n",
    "make_pruning_permanent(model)\n",
    "acc_final, f1_final = simple_evaluate(model, testloader, device, THRESHOLD)\n",
    "print(f\"Final result: acc: {acc_final:.4f}, {f1_final:.4f}, (drop: {(acc_base-acc_final)*100:.2f}%, {(f1_base - f1_final)*100:.2f}%)\")\n",
    "\n",
    "# Final Save\n",
    "# measure_sparsity(model)\n",
    "# save_folder = 'model_saves'\n",
    "# os.makedirs(save_folder, exist_ok=True)\n",
    "# save_path = os.path.join(save_folder, 'threshold_0.07_hybrid_Tr2019_Te2022_new_optimised.pth')\n",
    "# torch.save(model.state_dict(), save_path)\n",
    "# print(f\"Model saved to: {save_path}\")"
   ],
   "id": "5c59bd93ab11c67a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 2. Make pruning permanent and apply quantization to INT8 (currently INT32)",
   "id": "b653ccd245ca1cc8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch.quantization\n",
    "import os\n",
    "import time\n",
    "\n",
    "def print_size_of_model(model, label=\"\"):\n",
    "    torch.save(model.state_dict(), \"temp.p\")\n",
    "    size = os.path.getsize(\"temp.p\")\n",
    "    print(f\"Model: {label:<15} | Size: {size/1e6:.2f} MB\")\n",
    "    os.remove(\"temp.p\")\n",
    "    return size\n",
    "\n",
    "def measure_inference_speed(model, loader, device):\n",
    "    model.eval()\n",
    "    # Warmup\n",
    "    dummy_input, _ = next(iter(loader))\n",
    "    dummy_input = dummy_input.to(device)\n",
    "    for _ in range(10):\n",
    "        _ = model(dummy_input)\n",
    "\n",
    "    start = time.time()\n",
    "    count = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, _ in loader:\n",
    "            inputs = inputs.to(device)\n",
    "            _ = model(inputs)\n",
    "            count += inputs.size(0)\n",
    "            if count > 200: # Measure first 200 images only to save time\n",
    "                break\n",
    "    end = time.time()\n",
    "\n",
    "    latency = (end - start) / count * 1000 # ms per image\n",
    "    print(f\"Latency: {latency:.2f} ms/image\")\n",
    "    return latency\n",
    "\n",
    "# 1. Make Pruning Permanent\n",
    "print(\"\\nFinalizing Compression\")\n",
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, (torch.nn.Conv2d, torch.nn.Linear)):\n",
    "        if hasattr(module, 'weight_orig'):\n",
    "            torch.nn.utils.prune.remove(module, 'weight')\n",
    "\n",
    "print(\"Pruning masks removed. Weights are permanently sparse.\")\n",
    "size_fp32 = print_size_of_model(model, \"Pruned FP32\")\n",
    "\n",
    "# 2. Apply Dynamic Quantization (INT8)\n",
    "# We quantify Linear layers. Conv2d quantization usually requires 'Static' quantization\n",
    "# which is more complex, but let's try standard dynamic first as it's the easiest win for Transformers.\n",
    "quantized_model = torch.quantization.quantize_dynamic(\n",
    "    model.cpu(),\n",
    "    {torch.nn.Linear},\n",
    "    dtype=torch.qint8\n",
    ")\n",
    "\n",
    "print(\"\\nQuantization Results\")\n",
    "size_int8 = print_size_of_model(quantized_model, \"Quantized INT8\")\n",
    "\n",
    "reduction = (size_fp32 - size_int8) / size_fp32 * 100\n",
    "print(f\"Size Reduction: {reduction:.2f}%\")\n",
    "\n",
    "# 3. Save the Efficient Model\n",
    "save_folder = 'model_saves'\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "q_path = os.path.join(save_folder, 'threshold_0.27_hybrid_Tr2022_Te2019_optimised.pth')\n",
    "torch.save(quantized_model.state_dict(), q_path)\n",
    "print(f\"Efficient model saved to: {q_path}\")"
   ],
   "id": "118da4cb5c6b43f4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 3. Test performance on newly compressed model",
   "id": "ec043241a01bf906"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import time\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "\n",
    "def evaluate_quantized(model, loader, device='cpu'):\n",
    "    # MUST USE CPU due to pytorch\n",
    "    model.to('cpu')\n",
    "    model.eval()\n",
    "\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    start = time.time()\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in loader:\n",
    "            inputs = inputs.to('cpu')\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            probs = torch.softmax(outputs, dim=1)[:, 1]\n",
    "            # USE YOUR OPTIMAL THRESHOLD HERE\n",
    "            # 0.27 for train 2022, test 2019\n",
    "            # 0.07 for train 2019, test 2022\n",
    "            preds = (probs >= 0.27).long()\n",
    "\n",
    "            all_preds.extend(preds.numpy())\n",
    "            all_targets.extend(targets.numpy())\n",
    "\n",
    "    end = time.time()\n",
    "    acc = accuracy_score(all_targets, all_preds)\n",
    "    f1 = f1_score(all_targets, all_preds)\n",
    "    print(f\"NEW Compressed Model Accuracy: {acc:.4f}\")\n",
    "    print(f\"NEW Compressed Model F1: {f1:.4f}\")\n",
    "    print(f\"Inference Time: {end - start:.2f} seconds\")\n",
    "\n",
    "print(\"\\nTesting Efficient Model\")\n",
    "evaluate_quantized(quantized_model, testloader)"
   ],
   "id": "d63a79d87a4b1893"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Cell 1.2.2 2019 -> 2022\n",
    "# here, i wasn't iteratively increasing the pruning, it stayed the same\n",
    "# so, in other words, there was a cut of 2.93% of the network only in the beginning and the rest 5 steps are just fine tuning for some more epochs\n",
    "# so by mistake, giving it more epoch improved a lot the performance!!!!!\n",
    "\n",
    "# Goal: 15.0% resnet, 17.0% trans\n",
    "# Schedule: 6 steps, 10 epochs/step\n",
    "# Per step pruning rate - resnet: 0.0267, trans: 0.0306\n",
    "# Baseline before acc: 0.8476, F1: 0.8882\n",
    "#\n",
    "# Step 1/6\n",
    "# Applying pruning\n",
    "# Global Sparsity: 2.93%\n",
    "# Finetuning for 10 epochs\n",
    "#    Epoch 5/10 | Loss: 0.0782\n",
    "#    Epoch 10/10 | Loss: 0.0708\n",
    "# Step 1 result: acc: 0.8394 (drop: 0.82%)\n",
    "# Step 2/6\n",
    "# Applying pruning\n",
    "# Global Sparsity: 2.93%\n",
    "# Finetuning for 10 epochs\n",
    "#    Epoch 5/10 | Loss: 0.0663\n",
    "#    Epoch 10/10 | Loss: 0.0671\n",
    "# Step 2 result: acc: 0.8948 (drop: -4.72%)\n",
    "# Step 3/6\n",
    "# Applying pruning\n",
    "# Global Sparsity: 2.93%\n",
    "# Finetuning for 10 epochs\n",
    "#    Epoch 5/10 | Loss: 0.0660\n",
    "#    Epoch 10/10 | Loss: 0.0624\n",
    "# Step 3 result: acc: 0.8996 (drop: -5.19%)\n",
    "# Step 4/6\n",
    "# Applying pruning\n",
    "# Global Sparsity: 2.93%\n",
    "# Finetuning for 10 epochs\n",
    "#    Epoch 5/10 | Loss: 0.0602\n",
    "#    Epoch 10/10 | Loss: 0.0581\n",
    "# Step 4 result: acc: 0.8758 (drop: -2.82%)\n",
    "# Step 5/6\n",
    "# Applying pruning\n",
    "# Global Sparsity: 2.93%\n",
    "# Finetuning for 10 epochs\n",
    "#    Epoch 5/10 | Loss: 0.0584\n",
    "#    Epoch 10/10 | Loss: 0.0594\n",
    "# Step 5 result: acc: 0.8733 (drop: -2.57%)\n",
    "# Step 6/6\n",
    "# Applying pruning\n",
    "# Global Sparsity: 2.93%\n",
    "# Finetuning for 10 epochs\n",
    "#    Epoch 5/10 | Loss: 0.0531\n",
    "#    Epoch 10/10 | Loss: 0.0537\n",
    "# Step 6 result: acc: 0.8907 (drop: -4.31%)\n",
    "# Final result: acc: 0.8907, 0.9242, (drop: -4.31%, -3.60%)"
   ],
   "id": "eeeea2809f795255"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
