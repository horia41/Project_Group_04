{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 1. Unstructured Magnitude Pruning - finding lazy neurons (whose weights is for e.g. 0.000032) and turning them off",
   "id": "ac245f63a5f3c231"
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from cswin_fpn_hybrid.resnet50_cswin.new_model import ResNetCSWinHybrid\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils.prune as prune\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from torchvision.transforms import v2\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "import os\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    data_transforms = {\n",
    "        'train': v2.Compose([\n",
    "            v2.Resize((224, 224)),\n",
    "            # ------------------------------------ baseline augmentation\n",
    "            # v2.RandomHorizontalFlip(),\n",
    "            # v2.RandomVerticalFlip(),\n",
    "            # v2.ToTensor(),\n",
    "            # v2.Normalize([0.7553, 0.3109, 0.1059], [0.1774, 0.1262, 0.0863]),\n",
    "            # ------------------------------------ baseline augmentation\n",
    "\n",
    "            # ------------------------------------ new data augmentation added\n",
    "\n",
    "            # Geometric Transforms\n",
    "            v2.RandomHorizontalFlip(p=0.5),\n",
    "\n",
    "            v2.RandomRotation(degrees=15),\n",
    "            # Slight zoom/shift\n",
    "            v2.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "\n",
    "            # Color/Signal Transforms\n",
    "            v2.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3),\n",
    "\n",
    "            # Noise & Robustness\n",
    "            # Gaussian Blur helps ignore grain/noise\n",
    "            v2.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0)),\n",
    "\n",
    "            v2.ToTensor(),\n",
    "            # train 2022\n",
    "            v2.Normalize([0.7083, 0.2776, 0.0762], [0.1704, 0.1296, 0.0815]),\n",
    "            # train 2019\n",
    "            # v2.Normalize([0.7553, 0.3109, 0.1059], [0.1774, 0.1262, 0.0863]),\n",
    "\n",
    "            # Occlusion (The Precision Booster)\n",
    "            v2.RandomErasing(p=0.3, scale=(0.02, 0.15), ratio=(0.3, 3.3)),\n",
    "            # --------------------------------- new data augmentation added\n",
    "        ]),\n",
    "        'test': v2.Compose([\n",
    "            v2.Resize((224, 224)),\n",
    "            v2.ToTensor(),\n",
    "            # train 2022\n",
    "            v2.Normalize([0.7083, 0.2776, 0.0762], [0.1704, 0.1296, 0.0815])\n",
    "            # train 2019\n",
    "            # v2.Normalize([0.7553, 0.3109, 0.1059], [0.1774, 0.1262, 0.0863])\n",
    "        ]),\n",
    "    }\n",
    "\n",
    "    data_dir = 'DeepLearning_PlantDiseases-master/Scripts/PlantVillage_2_2022train_2019test'\n",
    "    # data_dir = 'DeepLearning_PlantDiseases-master/Scripts/PlantVillage_1_2019train_2022test'\n",
    "\n",
    "    dsets = {split: datasets.ImageFolder(os.path.join(data_dir, split), data_transforms[split])\n",
    "             for split in ['train', 'test']}\n",
    "\n",
    "    dset_loaders = {\n",
    "        'train': torch.utils.data.DataLoader(dsets['train'], batch_size=batch_size, shuffle=True, num_workers=4),\n",
    "        'test' : torch.utils.data.DataLoader(dsets['test'],  batch_size=batch_size, shuffle=False, num_workers=4),\n",
    "    }\n",
    "\n",
    "    return dset_loaders['train'], dset_loaders['test']\n",
    "\n",
    "def measure_sparsity(model):\n",
    "    # Calculates what % of the model is zeros\n",
    "    total_params = 0\n",
    "    zero_params = 0\n",
    "\n",
    "    for name, module in model.named_modules():\n",
    "        # check for standard layers\n",
    "        if isinstance(module, (nn.Conv2d, nn.Linear)):\n",
    "            # \"weight\" is the parameter\n",
    "            if hasattr(module, \"weight\"):\n",
    "                w = module.weight.data\n",
    "                total_params += w.numel()\n",
    "                zero_params += torch.sum(w == 0).item()\n",
    "\n",
    "    print(f\"Global Sparsity: {100. * zero_params / total_params:.2f}%\")\n",
    "    return zero_params / total_params\n",
    "\n",
    "def apply_pruning(model, amount_cnn, amount_trans):\n",
    "    print(f\"\\nStarting Pruning\")\n",
    "    print(f\"Target is {amount_cnn*100}% on ResNet part, {amount_trans*100}% on Transformer part\")\n",
    "    cnn_count, trans_count = 0, 0\n",
    "\n",
    "    for name, module in model.named_modules():\n",
    "        # We need to prune both Conv2d and Linear layers\n",
    "        if isinstance(module, (nn.Conv2d, nn.Linear)):\n",
    "            if \"stage3\" in name or \"stage4\" in name:\n",
    "                prune.l1_unstructured(module, name='weight', amount=amount_trans)\n",
    "                trans_count += 1\n",
    "            else:\n",
    "                prune.l1_unstructured(module, name='weight', amount=amount_cnn)\n",
    "                cnn_count += 1\n",
    "\n",
    "    print(f\"Pruning Applied: {cnn_count} layers at {amount_cnn} rate, {trans_count} layers at {amount_trans} rate.\")\n",
    "    print(\"Zeros injected.\")\n",
    "\n",
    "def simple_evaluate(model, loader, device, threshold):\n",
    "    #  quick eval to check damage\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in loader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            probs = torch.softmax(outputs, dim=1)[:, 1]\n",
    "            preds = (probs >= threshold).long()\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "\n",
    "    acc = accuracy_score(all_targets, all_preds)\n",
    "    f1 = f1_score(all_targets, all_preds)\n",
    "    return acc, f1\n",
    "\n",
    "\n",
    "def check_parameter_coverage(model):\n",
    "    total_params = 0\n",
    "    prunable_params = 0\n",
    "\n",
    "    print(f\"\\nPruning Coverage Analysis\")\n",
    "\n",
    "    for name, module in model.named_modules():\n",
    "        # Check if the module has parameters\n",
    "        if hasattr(module, 'weight') and module.weight is not None:\n",
    "            params = module.weight.numel()\n",
    "            total_params += params\n",
    "\n",
    "            # Is it one of the types we are targeting?\n",
    "            if isinstance(module, (nn.Conv2d, nn.Linear)):\n",
    "                prunable_params += params\n",
    "            else:\n",
    "                # These are the ones we are skipping\n",
    "                print(f\"Skipping: {name:<40} | Type: {type(module).__name__:<15} | Size: {params}\")\n",
    "\n",
    "    coverage = (prunable_params / total_params) * 100\n",
    "    print(\"-\" * 75)\n",
    "    print(f\"Total Params (Weights only): {total_params:,}\")\n",
    "    print(f\"Targeted Params (Conv+Linear): {prunable_params:,}\")\n",
    "    print(f\"Coverage: {coverage:.2f}%\")\n",
    "\n",
    "    if coverage > 95:\n",
    "        print(\"all good\")\n",
    "    else:\n",
    "        print(\"changed needed\")\n",
    "\n",
    "\n",
    "\n",
    "# 1. Load best Model\n",
    "model = ResNetCSWinHybrid(num_classes=2, resnet_pretrained=True, cswin_pretrained=True)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "batch_size = 128\n",
    "\n",
    "path = 'threshold_0.27_hybrid_Tr2022_Te2019.pth'\n",
    "model.load_state_dict(torch.load(path))\n",
    "\n",
    "trainloader, testloader = load_data()\n",
    "\n",
    "# 2. baseline stats\n",
    "# 0.27 for train 2022, test 2019\n",
    "# 0.07 for train 2019, test 2022\n",
    "threshold = 0.27\n",
    "acc_before, f1_before = simple_evaluate(model, testloader, device, threshold)\n",
    "# acc_before = 0.8908\n",
    "# f1_before = 0.8623\n",
    "print(f\"No pruning baseline acc, f1: {acc_before:.4f}, {f1_before:.4f}\")\n",
    "\n",
    "# 3. apply Pruning\n",
    "apply_pruning(model, amount_cnn=0.08, amount_trans=0.08)\n",
    "measure_sparsity(model)\n",
    "\n",
    "# 4. Check 'Broken' Stats (Before fine-tuning)\n",
    "print(\"Checking Pruned Accuracy (No Retraining)\")\n",
    "acc_after, f1_after = simple_evaluate(model, testloader, device, threshold)\n",
    "print(f\"Pruned Accuracy, F1: {acc_after:.4f}, {f1_after:.4f}\")\n",
    "print(f\"Drop due to pruning: {(acc_before - acc_after)*100:.2f}%, {(f1_before - f1_after)*100:.2f}%\")\n",
    "\n",
    "\n",
    "# Sanity check, see if rights params are targeted\n",
    "# check_parameter_coverage(model)\n",
    "\n",
    "# Note: Pruning adds 'mask' buffers. To make it permanent/saveable:\n",
    "# for name, module in model.named_modules():\n",
    "#     if isinstance(module, (nn.Conv2d, nn.Linear)):\n",
    "#         prune.remove(module, 'weight')"
   ],
   "id": "694a6fc124046936"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 2. Make pruning permanent and apply quantization to INT8 (currently INT32)",
   "id": "b653ccd245ca1cc8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch.quantization\n",
    "import os\n",
    "import time\n",
    "\n",
    "def print_size_of_model(model, label=\"\"):\n",
    "    torch.save(model.state_dict(), \"temp.p\")\n",
    "    size = os.path.getsize(\"temp.p\")\n",
    "    print(f\"Model: {label:<15} | Size: {size/1e6:.2f} MB\")\n",
    "    os.remove(\"temp.p\")\n",
    "    return size\n",
    "\n",
    "def measure_inference_speed(model, loader, device):\n",
    "    model.eval()\n",
    "    # Warmup\n",
    "    dummy_input, _ = next(iter(loader))\n",
    "    dummy_input = dummy_input.to(device)\n",
    "    for _ in range(10):\n",
    "        _ = model(dummy_input)\n",
    "\n",
    "    start = time.time()\n",
    "    count = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, _ in loader:\n",
    "            inputs = inputs.to(device)\n",
    "            _ = model(inputs)\n",
    "            count += inputs.size(0)\n",
    "            if count > 200: # Measure first 200 images only to save time\n",
    "                break\n",
    "    end = time.time()\n",
    "\n",
    "    latency = (end - start) / count * 1000 # ms per image\n",
    "    print(f\"Latency: {latency:.2f} ms/image\")\n",
    "    return latency\n",
    "\n",
    "# 1. Make Pruning Permanent\n",
    "print(\"\\nFinalizing Compression\")\n",
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, (torch.nn.Conv2d, torch.nn.Linear)):\n",
    "        if hasattr(module, 'weight_orig'):\n",
    "            torch.nn.utils.prune.remove(module, 'weight')\n",
    "\n",
    "print(\"Pruning masks removed. Weights are permanently sparse.\")\n",
    "size_fp32 = print_size_of_model(model, \"Pruned FP32\")\n",
    "\n",
    "# 2. Apply Dynamic Quantization (INT8)\n",
    "# We quantify Linear layers. Conv2d quantization usually requires 'Static' quantization\n",
    "# which is more complex, but let's try standard dynamic first as it's the easiest win for Transformers.\n",
    "quantized_model = torch.quantization.quantize_dynamic(\n",
    "    model.cpu(),\n",
    "    {torch.nn.Linear},\n",
    "    dtype=torch.qint8\n",
    ")\n",
    "\n",
    "print(\"\\nQuantization Results\")\n",
    "size_int8 = print_size_of_model(quantized_model, \"Quantized INT8\")\n",
    "\n",
    "reduction = (size_fp32 - size_int8) / size_fp32 * 100\n",
    "print(f\"Size Reduction: {reduction:.2f}%\")\n",
    "\n",
    "# 3. Save the Efficient Model\n",
    "save_folder = 'model_saves'\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "q_path = os.path.join(save_folder, 'threshold_0.27_hybrid_Tr2022_Te2019_optimised.pth')\n",
    "torch.save(quantized_model.state_dict(), q_path)\n",
    "print(f\"Efficient model saved to: {q_path}\")"
   ],
   "id": "118da4cb5c6b43f4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 3. Test performance on newly compressed model",
   "id": "ec043241a01bf906"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import time\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "\n",
    "def evaluate_quantized(model, loader, device='cpu'):\n",
    "    # MUST USE CPU due to pytorch\n",
    "    model.to('cpu')\n",
    "    model.eval()\n",
    "\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    start = time.time()\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in loader:\n",
    "            inputs = inputs.to('cpu')\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            probs = torch.softmax(outputs, dim=1)[:, 1]\n",
    "            # USE YOUR OPTIMAL THRESHOLD HERE\n",
    "            # 0.27 for train 2022, test 2019\n",
    "            # 0.07 for train 2019, test 2022\n",
    "            preds = (probs >= 0.27).long()\n",
    "\n",
    "            all_preds.extend(preds.numpy())\n",
    "            all_targets.extend(targets.numpy())\n",
    "\n",
    "    end = time.time()\n",
    "    acc = accuracy_score(all_targets, all_preds)\n",
    "    f1 = f1_score(all_targets, all_preds)\n",
    "    print(f\"NEW Compressed Model Accuracy: {acc:.4f}\")\n",
    "    print(f\"NEW Compressed Model F1: {f1:.4f}\")\n",
    "    print(f\"Inference Time: {end - start:.2f} seconds\")\n",
    "\n",
    "print(\"\\nTesting Efficient Model\")\n",
    "evaluate_quantized(quantized_model, testloader)"
   ],
   "id": "d63a79d87a4b1893"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
